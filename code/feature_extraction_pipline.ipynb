{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c4246-efb4-4a24-81c5-0bf43ebed9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import helperfunctions as hf # helper functions written in helperfunctions.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import dit\n",
    "from dit.other import tsallis_entropy\n",
    "import math\n",
    "import pywt\n",
    "from kymatio import Scattering2D\n",
    "import cv2 as cv\n",
    "import medpy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.restoration import denoise_nl_means\n",
    "from pytictoc import TicToc\n",
    "\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d23718d-f13e-4403-9166-a42684e1b312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nicklu/JHU/2022Fall/Computer Vision/final project/fall2022CV/code/../BRATS2015_Training/BRATS2015_Training/HGG\n",
      "/Users/nicklu/JHU/2022Fall/Computer Vision/final project/fall2022CV/code/../BRATS2015_Training/BRATS2015_Training/LGG\n",
      "Dataset found!\n"
     ]
    }
   ],
   "source": [
    "# input folder path\n",
    "HGG_folderpath = os.path.join(os.getcwd(), \"..\", \"BRATS2015_Training\", \"BRATS2015_Training\", \"HGG\")\n",
    "LGG_folderpath = os.path.join(os.getcwd(), \"..\", \"BRATS2015_Training\", \"BRATS2015_Training\", \"LGG\")\n",
    "print(HGG_folderpath)\n",
    "print(LGG_folderpath)\n",
    "\n",
    "# check if the folders exist\n",
    "if os.path.isdir(HGG_folderpath) and os.path.isdir(LGG_folderpath):\n",
    "    print(\"Dataset found!\")\n",
    "else:\n",
    "    print(\"ERROR: Dataset not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c986a5-a657-49a1-880a-d2aa6ec5a732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of HGG subjects: 220\n",
      "Total number of LGG subjects: 54\n"
     ]
    }
   ],
   "source": [
    "# Use the function hf.get_filepaths to get the target OT file and one type of fMRI file\n",
    "\n",
    "# Ex. list all *.mha files in the HGG category\n",
    "# Note: OT - true tumor label; the others are four different kinds of fMRI\n",
    "HGG_OT_files = hf.get_filepaths(HGG_folderpath, MRtype=['OT'])\n",
    "HGG_MR_Flair_files = hf.get_filepaths(HGG_folderpath, MRtype=['MR_Flair'])\n",
    "HGG_MR_T1_files = hf.get_filepaths(HGG_folderpath, MRtype=['MR_T1'])\n",
    "HGG_MR_T1c_files = hf.get_filepaths(HGG_folderpath, MRtype=['MR_T1c'])\n",
    "HGG_MR_T2_files = hf.get_filepaths(HGG_folderpath, MRtype=['MR_T2'])\n",
    "\n",
    "LGG_OT_files = hf.get_filepaths(LGG_folderpath, MRtype=['OT'])\n",
    "LGG_MR_Flair_files = hf.get_filepaths(LGG_folderpath, MRtype=['MR_Flair'])\n",
    "LGG_MR_T1_files = hf.get_filepaths(LGG_folderpath, MRtype=['MR_T1'])\n",
    "LGG_MR_T1c_files = hf.get_filepaths(LGG_folderpath, MRtype=['MR_T1c'])\n",
    "LGG_MR_T2_files = hf.get_filepaths(LGG_folderpath, MRtype=['MR_T2'])\n",
    "\n",
    "print(\"Total number of HGG subjects:\", len(HGG_OT_files))\n",
    "print(\"Total number of LGG subjects:\", len(LGG_OT_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f04e341-4476-425e-9f45-6cf32f4f93f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign filepaths - use OT files and one type of corresponding fMRI files at a time\n",
    "OT_paths = HGG_OT_files\n",
    "MR_paths = HGG_MR_Flair_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "312c880e-922b-47a0-a621-14de12234ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files: 220\n",
      "8\n",
      "Elapsed time is 32.978263 seconds.\n"
     ]
    }
   ],
   "source": [
    "# feature extraction - may take some time for each slice\n",
    "print(\"Total number of files:\", len(OT_paths))\n",
    "\n",
    "# extract feature for each file\n",
    "# for file_id in range(1):\n",
    "#     print(\"Start processing file {}/{}\".format(file_id+1, len(OT_paths)), end=' ')\n",
    "#     Z = hf.get_recommended_slices_id(OT_paths, file_id)\n",
    "#\n",
    "#     # extract feature for each slice\n",
    "#     slice_cnt = 0\n",
    "#     for slice_id in range(Z, Z+1):\n",
    "#         slice_cnt += 1\n",
    "#         print(slice_cnt, end=' ')\n",
    "#         feature = hf.extract_feature_one_slice(OT_paths, MR_paths, file_id, slice_id) # an array of features\n",
    "#         print(\"succeeded\")\n",
    "#         break\n",
    "\n",
    "def process(file_id):\n",
    "    print(f\"Start processing file {file_id}\")\n",
    "    Z = hf.get_recommended_slices_id(OT_paths, file_id)\n",
    "\n",
    "    # extract feature for each slice\n",
    "    slice_cnt = 0\n",
    "    for slice_id in range(Z, Z+1):\n",
    "        slice_cnt += 1\n",
    "        print(slice_cnt, end=' ')\n",
    "        feature = hf.extract_feature_one_slice(OT_paths, MR_paths, file_id, slice_id) # an array of features\n",
    "        print(\"succeeded\")\n",
    "        return feature\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)\n",
    "t = TicToc()\n",
    "t.tic()\n",
    "dataset = Parallel(n_jobs=num_cores)(delayed(process)(file_id) for file_id in range(1))\n",
    "t.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41066dd1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.save('LGG_dataset.npy', dataset, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be79b61-4c9c-480d-9c3a-e857c7bad892",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('LGG_dataset.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28437392",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa4ada",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1466b-5484-4551-9012-d886dfdc7f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c7ce4-ead2-4550-8459-6f08ca8b2201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8b34b0c4-82ca-422b-b8eb-9b63d4ebca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# data is an array of size (sample size * feature dimension)\n",
    "# label is an array of size (sample size, )\n",
    "# Assume HGG and LGG are 0/1 labels\n",
    "N = 20 # sample size\n",
    "D = 100 # feature dimension\n",
    "data = np.random.random((N, D))\n",
    "label = [i[0] for i in np.random.randint(0, 2, (N, 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4fb66bc4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>corr_direction</th>\n",
       "      <th>corr_pval</th>\n",
       "      <th>corr_sig_bc_05</th>\n",
       "      <th>corr_sig_bh_05</th>\n",
       "      <th>corr_sig_bc_01</th>\n",
       "      <th>corr_sig_bh_01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.223501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.935767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.425995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.061094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.153524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.118371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.619161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       corr  corr_direction  corr_pval  corr_sig_bc_05  corr_sig_bh_05  \\\n",
       "0 -0.223501             0.0   0.343525             0.0             0.0   \n",
       "1  0.019259             1.0   0.935767             0.0             0.0   \n",
       "2  0.425995             1.0   0.061094             0.0             0.0   \n",
       "3 -0.153524             0.0   0.518138             0.0             0.0   \n",
       "4 -0.118371             0.0   0.619161             0.0             0.0   \n",
       "\n",
       "   corr_sig_bc_01  corr_sig_bh_01  \n",
       "0             0.0             0.0  \n",
       "1             0.0             0.0  \n",
       "2             0.0             0.0  \n",
       "3             0.0             0.0  \n",
       "4             0.0             0.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bonferroni_correction(pVal, alpha=0.05):\n",
    "    \"\"\"Perform an alpha-level test with Bonferroni correction.\n",
    "    pVal: array-like\n",
    "    return an array of 0 (not significant) and 1 (significant)\n",
    "    \"\"\"\n",
    "    bonferroni_correction = alpha / len(pVal)\n",
    "    result = np.zeros(len(pVal))\n",
    "    result[np.where(pVal<=bonferroni_correction)] = 1\n",
    "    return result\n",
    "\n",
    "def benjamini_hochberg(pVal, fdr=0.01):\n",
    "    \"\"\"Perform an alpha-level test using the Benjamini Hochberg estimator.\n",
    "    pVal: array-like\n",
    "    return an array of 0 (not significant) and 1 (significant)\n",
    "    \"\"\"\n",
    "    result = np.zeros(len(pVal))\n",
    "    n = len(pVal)\n",
    "    pVal_index = np.argsort(pVal)\n",
    "    valid = np.where(pVal[pVal_index]<=np.arange(1, n+1)*fdr/n)[0]\n",
    "    if len(valid) == 0:\n",
    "        return result\n",
    "    cutoff = valid[-1]\n",
    "    result[pVal_index[:(cutoff+1)]] = 1\n",
    "    return result    \n",
    "\n",
    "\n",
    "columns = ['feature' + str(i) for i in range(D)]\n",
    "data_df = pd.DataFrame(data, columns=columns)\n",
    "y = label\n",
    "corr = data_df.apply(lambda x : stats.pearsonr(x, y))\n",
    "corr_pval = corr.loc[1].values\n",
    "corr = corr.loc[0].values\n",
    "corr_abs = np.abs(corr)\n",
    "# 1 means that the feature is larger in label 1\n",
    "corr_direction = [int(corr[i]>0) for i in range(len(corr))]\n",
    "\n",
    "result = np.array([corr, corr_direction, corr_pval]).T\n",
    "result_df = pd.DataFrame(result, columns=[\"corr\", \"corr_direction\", \"corr_pval\"])\n",
    "for fdr, fdr_str in [[0.05, '05'], [0.01, '01']]:\n",
    "    result_df['corr_sig_bc_'+fdr_str] = bonferroni_correction(result_df['corr_pval'].values, alpha=fdr)\n",
    "    result_df['corr_sig_bh_'+fdr_str] = benjamini_hochberg(result_df['corr_pval'], fdr=fdr)\n",
    "\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ce4f8bf-b02e-471e-9082-6aae4bada5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>corr_direction</th>\n",
       "      <th>corr_pval</th>\n",
       "      <th>corr_sig_bc_05</th>\n",
       "      <th>corr_sig_bh_05</th>\n",
       "      <th>corr_sig_bc_01</th>\n",
       "      <th>corr_sig_bh_01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [corr, corr_direction, corr_pval, corr_sig_bc_05, corr_sig_bh_05, corr_sig_bc_01, corr_sig_bh_01]\n",
       "Index: []"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if any of corr_sig_bc_05 / corr_sig_bc_01 / corr_sig_bh_05 / corr_sig_bh_01 is 1, then that feature is significantly correlated with the label\n",
    "result_df.loc[result_df['corr_sig_bc_05']==1, ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
